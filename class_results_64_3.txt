Using all (16) CPUs....
Using all (1) GPUs...
Training begins ...
Epoch: 1 completed in: 36.12621879577637s, Total time: 0.6021036545435587 mins, loss is: 0.27778342366218567
Epoch: 2 completed in: 36.79216289520264s, Total time: 1.2153079628944397 mins, loss is: 0.21666352450847626
Epoch: 3 completed in: 36.5741822719574s, Total time: 1.8248796979586284 mins, loss is: 0.2050981968641281
Validation loss: 0.17096436023712158, Accuracy: 0.9312252288215335, Total time: 2.428062661488851 mins
Epoch: 4 completed in: 37.283138036727905s, Total time: 3.049450361728668 mins, loss is: 0.19913893938064575
Epoch: 5 completed in: 36.905680894851685s, Total time: 3.6645471374193828 mins, loss is: 0.19500504434108734
Epoch: 6 completed in: 37.211520195007324s, Total time: 4.284741405646006 mins, loss is: 0.19162772595882416
Validation loss: 0.1660548448562622, Accuracy: 0.9338199652134241, Total time: 4.900406197706858 mins
Epoch: 7 completed in: 38.347792625427246s, Total time: 5.539538204669952 mins, loss is: 0.18859612941741943
Epoch: 8 completed in: 37.697742223739624s, Total time: 6.167835986614227 mins, loss is: 0.18549661338329315
Epoch: 9 completed in: 37.835108280181885s, Total time: 6.798423258463542 mins, loss is: 0.18235982954502106
Validation loss: 0.16314826905727386, Accuracy: 0.9359869978044538, Total time: 7.431007881959279 mins
Epoch: 10 completed in: 38.05841517448425s, Total time: 8.06531689564387 mins, loss is: 0.17950037121772766
Epoch: 11 completed in: 37.80605959892273s, Total time: 8.695420142014822 mins, loss is: 0.17631401121616364
Epoch: 12 completed in: 37.58756160736084s, Total time: 9.321881651878357 mins, loss is: 0.1734321117401123
Validation loss: 0.16552819311618805, Accuracy: 0.9358444298708335, Total time: 9.952204076449076 mins
Epoch: 13 completed in: 36.37064266204834s, Total time: 10.558383584022522 mins, loss is: 0.17016813158988953
Epoch: 14 completed in: 36.81657361984253s, Total time: 11.171995306015015 mins, loss is: 0.16745290160179138
Epoch: 15 completed in: 37.54377508163452s, Total time: 11.797726992766062 mins, loss is: 0.16365627944469452
Traceback (most recent call last):
  File "lstm_classification.py", line 274, in <module>
    main()
  File "lstm_classification.py", line 266, in main
    loss_function 
  File "lstm_classification.py", line 147, in validate
    predictions = rnn(_input)
  File "/home/yihe/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "lstm_classification.py", line 102, in forward
    out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))
  File "/home/yihe/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/yihe/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 564, in forward
    return self.forward_tensor(input, hx)
  File "/home/yihe/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 543, in forward_tensor
    output, hidden = self.forward_impl(input, hx, batch_sizes, max_batch_size, sorted_indices)
  File "/home/yihe/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 526, in forward_impl
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 10.76 GiB total capacity; 9.03 GiB already allocated; 3.44 MiB free; 50.50 KiB cached)
